# Lighteval

ü§ó Lighteval is your all-in-one toolkit for evaluating Large Language Models (LLMs) across multiple backends‚Äîwhether it's
[Transformers](https://github.com/huggingface/transformers),
[Text Generation Inference (TGI)](https://github.com/huggingface/text-generation-inference),
[Inference Providers](https://huggingface.co/docs/huggingface_hub/en/guides/inference),
[VLLM](https://github.com/vllm-project/vllm), or
[Nanotron](https://github.com/huggingface/nanotron)‚Äîwith
ease. Dive deep into your model's performance by saving and exploring detailed,
sample-by-sample results to debug and see how your models stack up.

## Key Features

### üöÄ **Multi-Backend Support**
Evaluate your models using the most popular and efficient inference backends:
- **Transformers**: Standard Hugging Face models with full customization
- **VLLM**: High-performance inference with optimized memory usage
- **SGLang**: Fast and efficient model serving
- **TGI**: Production-ready text generation inference
- **Inference Endpoints**: Cloud-based model deployment
- **LiteLLM**: Unified interface for multiple LLM providers
- **Nanotron**: Distributed training and evaluation

### üìä **Comprehensive Evaluation**
- **Extensive Task Library**: 100+ pre-built evaluation tasks
- **Custom Task Creation**: Build your own evaluation tasks
- **Flexible Metrics**: Support for custom metrics and scoring
- **Detailed Analysis**: Sample-by-sample results for deep insights

### üîß **Easy Customization**
Customization at your fingertips: create [new tasks](adding-a-custom-task) and
[metrics](adding-a-new-metric) tailored to your needs, or browse all our existing tasks and metrics.

### ‚òÅÔ∏è **Seamless Integration**
Seamlessly experiment, benchmark, and store your results on the Hugging Face Hub, S3, or locally.

## Quick Start

### Installation

```bash
pip install lighteval
```

### Basic Usage

```bash
# Evaluate a model using Transformers backend
lighteval accelerate \
    "model_name=openai-community/gpt2" \
    "leaderboard|truthfulqa:mc|0|0"

# Evaluate using VLLM for better performance
lighteval vllm \
    "model_name=HuggingFaceH4/zephyr-7b-beta,dtype=float16" \
    "leaderboard|gsm8k|3|1"
```

### Save Results

```bash
# Save locally
lighteval accelerate \
    "model_name=openai-community/gpt2" \
    "leaderboard|truthfulqa:mc|0|0" \
    --output-dir ./results

# Push to Hugging Face Hub
lighteval accelerate \
    "model_name=openai-community/gpt2" \
    "leaderboard|truthfulqa:mc|0|0" \
    --push-to-hub \
    --results-org your-username
```
